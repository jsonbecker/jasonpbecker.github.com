---

title       : EDUC1160 Evaluating the Impact of Social Programs 
subtitle    : Causal Research Design
author      : Jason Becker
job         : Harvard Strategic Data Fellow, AISR/PPSD
framework   : io2012    # {io2012, html5slides, shower, dzslides, ...}
highlighter : prettify  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
theme       : default
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}

---

## Course Description

This course will provide an overview of education policy research with an 
emphasis on strategies for measuring *causal impacts*.

Today:

1. Relation to other courses
2. Course objectives (with your help)
3. Course Outline (kind of)
4. Assignments and Assessments (subject to change)
5. Why is education research unique? Why is it difficult to study?

---

## Relation to Other Courses

- **Course will build on discipline-based research**
	- Economics of Education; Psychology/ Human Development, 
	  Sociology of Education, Political Science

- **You should know some statistics**
	- Introductory statistics (i.e. an understanding of how to interpret 
		Ordinary Least Squares (OLS) regression results and a basic familiarity with
		a statistical software package of choice.)
  
- The course materials were originally written by someone else!
  - I owe a great deal of gratitude to Angela Boatman who redesigned this class marvelously and whose lecture notes I am adapting fairly faithfully.

---

## The President Loves You

"The question we ask today is not whether our government is too big or too 
small, but whether it works — whether it helps families find jobs at a decent 
wage, care they can afford, a retirement that is dignified. Where the answer is 
yes, we intend to move forward. Where the answer is no, programs will end."

President Barack Obama, January 20, 2009

---

## Course Objectives

1. Make you informed, critical consumers of education policy research
2. Equip you with the conceptual and practical tools to (begin to) conduct your 
own research (maybe?)
3. Expose you to findings from recent evaluations of a wide range of programs.

---

## Guiding Questions for the Course

- What kinds of research designs are most appropriate? What are the strengths and limitations of different designs?
- What kinds of data are needed?
- What statistical methods are best used to process
these data?
- How can results be interpreted so that policymakers are best informed?

---

## Potential Topics

>- Class size
>- Charter schools/ pilot schools
>- Teach For America versus traditional certification 
>- Neighborhood effects on educational outcomes
>- Measuring teacher effectiveness
>- High intensity tutoring
>- Early childhood education

---

## Course Outline
>-1. The evaluation problem and randomized experiments
>-2. Estimating causal effects using observational data Differences-in-differences
  - Fixed Effects
  - Instrumental Variables
  - Regression Discontinuity designs 
  - Propensity score matching

---

## Logistics

- Office hours by appointment for now.
- Email me ahead of time if you're going to miss class.
- We are going to use Canvas
- First half syllabus on Monday
- Redesign based on size

---

## Materials

Primary text: Methods Matter: Improving Causal Inference in Educational Research by Richard Murnane and John Willett (2011)
  - There are copies at the bookstore, in the Rock, and on Canvas

- Scholarly papers
  - What research question(s) does the paper address?
  - What answers does the author provide to his or her research questions?
  - What theory informs the design of the research?
  - What analytical method(s) does the author use in addressing his or her research question(s)?
  - What data set(s) does the author use?
  - What are the potential policy implications of the results presented in the paper?
  - What are the strengths of the research? 
  - What are the weaknesses of the research?

---

## Assignments and Assessment
- Attendance and participation: 15%
  - This includes Canvas, and especially includes the weekly quiz/survey
- Two Computer Assignments: 30% (15% each) 
  - R? STATA? Nothing?
- Two Take-Home Exams: 30%
  - Definitely will have 1.
- Final paper: 25%
  - May swap one of the take-home exams.


---

## Final Paper/Big Paper
>- A reform happening in RI schools.
  >- Transformation is a good place to look
  >- RTT is another good one.
>- 150-word abstract written for a lay audience.
>- Origins of the policy/program and the problem it is trying to address.
>- Short description of program design and implementation.
>- Evaluation of existing evaluation of similar reform effort with proposals for how
they could be improved and implemented in RI (this is the bulk of the paper)
>- Summary of their implications for policymaking 

---

## Questions?

---

## Research Questions
4 categories of questions:
- Descriptive questions
- Association questions
- What works (causal) questions
- Why questions (identify paths of influence between cause and effect)

### ￼Why is education research unique?
- Outcome can be difficult to measure (learning)
- Many variables go into learning
- Ideology intervenes, especially when reporting unpopular results
- Field is guided by professional wisdom, intuition, creative expression
- What is politically popular might not be scientifically supported
- Net effects are likely to be relatively small

---

## ￼What Makes Good Research?
- A clear research question
- A clear definition
- A clear understanding of theory
  - Careful identification of the variables of interest
  - Outcome variables
  - Question predictors (assignment variables) 
  - Covariates/ control variables

---

## Early Examples

Hanushek looked at test scores at the start and end of third grader in 
California schools in 1971. He also collected lots of information about the
classrooms students were in, such as class size, teacher experience, and teacher
credentials/degrees. He found that schooling did matter-- there was variance in
different schools and different classrooms-- but did not find that any of the
popular cost drivers mattered. 

**Many challenged this finding. Why?**

---

## Why theory?

>-Theory provides a schema/system/framework to:
  - Hypothesize relationships
  - Predict direction of relationships
  - Identify input measures and output measures

>-Deductive Reasoning
  - Develop a specific hypotheses from a general theory
>-Inductive Reasoning
  - First observe a pattern, then try to explain what you have observed by 
  generalizing it


---

## Partial v. General Equilibrium
- Partial Equilibrium
 - Look at the impacts in a box smaller than the universe.
- General Equilibrium
 - Look at the impacts in full context, with many subtle effects on related 
 systems
 
>-Mandatory Class Size Reductions:
  - Guided by partial equilibrium findings
  - But some things are different when applied broadly at the state level.
  
>-Vouchers

---

## Importance of Theory

- Provides guidance about the question to ask
- Informs the key constructs to measure
- Suggests the direction of relationships

- Common examples:
  - Human Capital theory
  - Market Signaling theory
  - Bourdieu’s Social Reproduction theory

---

##  Causal Research

### John Stuart Mill’s 3 Critical Conditions

1. Cause comes before effect
2. Different levels of cause lead to different levels of effect
3. There can be no other alternative explanations for the link between cause and effect other than that X really does cause Y
  - Random assignment discounts all other possible explanations

---

## The Evaluation Challenge

You want to know what would have happened in the absence of a program, however, it is often very difficult to identify the correct comparison group.

---

## Old Biff

![](images/oldbiff.jpg)

---
## To new Biff

![](images/newbiff.jpg)

---

## The Evaluation Challenge

### Formally:


If your **comparison group** does a poor job of estimating the **counterfactual** of the treatment group, your estimate of the treatment effect will be *biased*.

---

## ￼Difficulty selecting the comparison group

### Selection bias 

>- Participants are self selected based on unobserved characteristics or selected by someone else based on non-random characteristics
  >- The most motivated students apply to a program 
  >- Results will be biased upwards

>- Picking the students who need the program the most 
  >- Results will be bias downwards

>- Primary sources of selection bias: Motivation/ Ability

---

## Potential Problems with Experiments

>- Placebo effect- Participation in a study causes a change in behavior/ outcomes
>- Ethical Issues- evidence of harm in offering or withholding a treatment
>- Duration- Takes time to see changes in behavior
>- Attrition
>- Costs
>- Substitution of alternative treatment- control group seeks out new treatment
>- Treatment group doesn’t take up the treatment- ―intent to treat‖ effect

---

## Ethics in experimentation

>- Denial of services or benefits to members of the control group
>- Ineffective programs can waste valuable resources
>- General rule: Leave the individual no worse off than she would have been in the absence of the experiment

---

## Internal and External Validity

>- **Internal validity:**  the statistical inferences about causal effects are valid for the population being studied.  
  - There are no rival explanations for the statistical relationship between the treatment and the outcomes


>- **External validity**:  the statistical inferences can be *generalized* from the population and setting studied to other populations and settings.

---

## Readings

### By Friday, Feb 1:

1. Murnane & Willett (2011), Chapter 5 

2. Schanzenbach, D. W. (2007).  “What researchers have 
learned from Project STAR”.  Brookings papers on 
education policy: 2006-07: pp. 205-228.

3. Raudenbush

### Lectures

Will be posted at: [http://www.jsonbecker.com/EDUC1160](http://www.jsonbecker.com/EDUC1160)

---